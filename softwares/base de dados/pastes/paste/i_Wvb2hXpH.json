{
 "espireDate": "N",
 "format": "text",
 "jSonReasons": [
  "re_sql",
  "kw_error",
  "lg_en",
  "kw_pass",
  "re_email"
 ],
 "key": "Wvb2hXpH",
 "pasteDate": "Feb 20, 2018, 7:11:21 PM",
 "relevancy": 2.0,
 "relevant": false,
 "text": "#!/usr/bin/env python\n\"\"\"\nWalk a sitemap and report timings and stuff.\n\nCopyright (c) 2008  Dustin Sallings <dustin@spy.net>\n\"\"\"\n\nimport sys\nimport time\nimport getopt\nimport random\n\nfrom twisted.web import client, sux\nfrom twisted.internet import reactor, defer, error\n\nR=random.Random()\ndefault_sample_size=5\nCONCURRENCY=5\npage_request_count=2\n\nmap_semaphore = defer.DeferredSemaphore(tokens=1)\nsemaphore = defer.DeferredSemaphore(tokens=CONCURRENCY)\n\nclass CountingFile(object):\n    \"\"\"A file-like object that just counts what's written to it.\"\"\"\n    def __init__(self):\n        self.written=0\n    def write(self, b):\n        self.written += len(b)\n    def close(self):\n        pass\n    def open(self):\n        pass\n    def read(self):\n        return None\n\nclass SitemapFile(sux.XMLParser):\n    \"\"\"A file-like thingy that parses sitemap results with SUX.\"\"\"\n    def __init__(self):\n        self.maps=[]\n        self.pages=[]\n        self.connectionMade()\n        self.inLoc=False\n        self.current=None\n        self.data=None\n    def write(self, b):\n        self.dataReceived(b)\n    def close(self):\n        self.connectionLost(error.ConnectionDone())\n    def open(self):\n        pass\n    def read(self):\n        return None\n\n    # XML Callbacks\n    def gotTagStart(self, name, attrs):\n        if name == 'loc':\n            self.data=[]\n            self.inLoc=True\n        elif name == 'sitemapindex':\n            self.current=self.maps\n        elif name == 'urlset':\n            self.current=self.pages\n\n    def gotTagEnd(self, name):\n        self.inLoc=False\n        if name == 'loc':\n            self.current.append(''.join(self.data))\n            self.data=None\n\n    def gotText(self, data):\n        if self.inLoc:\n            self.data.append(data)\n\ndef sample_size_for(url):\n    return default_sample_size\n\ndef process_sitemap(url, x):\n    start=time.time()\n    def f(v):\n        print \"+ %s ok %.3fs\" % (url, time.time() - start)\n        pages=x.pages\n        maps=x.maps\n        print \". found %d pages and %d maps\" % (len(pages), len(maps))\n        l=[map_semaphore.run(fetch_sitemap, m) for m in maps]\n        tofetch=pages\n        sample_size = sample_size_for(url)\n        if len(tofetch) > sample_size:\n            tofetch=R.sample(tofetch, sample_size)\n        print \". Fetching %d/%d from %s\" % (len(tofetch), len(pages), url)\n        for u in tofetch:\n            l.append(semaphore.run(fetch_page, u))\n        rv = defer.DeferredList(l)\n        return rv\n    return f\n\ndef report_error(url):\n    start=time.time()\n    def f(v):\n        print \"! Error on %s: %s\" % (url, v.getErrorMessage())\n        sys.stdout.flush()\n    return f\n\ndef fetch_page(url, count=1):\n    cf = CountingFile()\n    start = time.time()\n    def onSuccess(value):\n        print \"- %d %s ok %d bytes in %.3f\" % (count,\n            url, cf.written, time.time() - start)\n        if count < page_request_count:\n            return fetch_page(url, count+1)\n    return client.downloadPage(url, cf).addCallbacks(\n        callback=onSuccess,\n        errback=report_error)\n\ndef fetch_sitemap(url):\n    x=SitemapFile()\n    return client.downloadPage(url, x).addCallbacks(\n        callback=process_sitemap(url, x),\n        errback=report_error(url))\n\ndef usage():\n    sys.stderr.write(\"\"\"Usage %s [-c n] [-m n] [-n n] [-r n] url\n\nOptions:\n  -c n   - (page concurrency) Allow at most n concurrent page requests.\n  -m n   - (map concurrency) Allow at most n concurrent map requests.\n  -n n   - Ask for each page n times.\n  -r n   - Take a random sample of n pages.\n\"\"\" % sys.argv[0])\n    sys.exit(64)\n\nif __name__ == '__main__':\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], 'c:m:n:r:')\n    except getopt.GetoptError:\n        usage()\n    for o,v in opts:\n        if o == '-c':\n            semaphore = defer.DeferredSemaphore(tokens=int(v))\n        if o == '-m':\n            map_semaphore = defer.DeferredSemaphore(tokens=int(v))\n        if o == '-n':\n            page_request_count = int(v)\n        if o == '-r':\n            default_sample_size = int(v)\n\n    try:\n        url = args[0]\n    except IndexError:\n        usage()\n    fetch_sitemap(url).addBoth(lambda x: reactor.stop())\n    reactor.run()",
 "title": ""
}