{
 "espireDate": "N",
 "format": "text",
 "jSonReasons": [
  "kw_down",
  "lg_en"
 ],
 "key": "egeUcEXJ",
 "pasteDate": "Feb 12, 2018, 4:55:12 AM",
 "relevancy": 0.0,
 "relevant": false,
 "text": "#!/usr/bin/env python\n\nfrom __future__ import print_function\nimport argparse\nfrom collections import OrderedDict\nimport csv\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\n\nparser = argparse.ArgumentParser()\nparser.add_argument('incoming', help='CSV export of transactions')\nparser.add_argument('outgoing', help='CSV export of internal transactions')\nargs = parser.parse_args()\n\n# A place to gather the incoming transaction data\ndata_in = OrderedDict()\n\nwith open(args.incoming) as f:\n\tincoming = csv.reader(f)\n\t# Skip CSV header row\n\tnext(incoming)\n\tfor _,_,timestamp,_,_,_,_,value_in,value_out,_,_,_,_,_,_ in incoming:\n\t\t# Sanity check, just in case\n\t\tassert not float(value_out)\n\t\t# Round the timestamp down to the last 10-minute mark\n\t\ttimestamp = datetime.utcfromtimestamp(int(timestamp))\n\t\trounded_minute = timestamp.minute // 10 * 10\n\t\ttimestamp = timestamp.replace(minute=rounded_minute, second=0, microsecond=0)\n\t\t# First parsed row, store initial record \n\t\tif not data_in:\n\t\t\tfirst_timestamp = timestamp\n\t\t\tdata_in[timestamp] = Decimal(value_in)\n\t\t\tlast_timestamp = timestamp\n\t\t\tcontinue\n\t\t# We've already had a transaction for this 10-minute period, add this one to it\n\t\tif timestamp in data_in:\n\t\t\tdata_in[timestamp] += Decimal(value_in)\n\t\t\tlast_timestamp = timestamp\n\t\t\tcontinue\n\t\t# Fill in 10-minute periods without transactions with the total from\n\t\t# the previous period (probably unnecessary, but avoids gaps)\n\t\twhile last_timestamp + timedelta(minutes=10) < timestamp:\n\t\t\tdata_in[last_timestamp + timedelta(minutes=10)] = data_in[last_timestamp]\n\t\t\tlast_timestamp += timedelta(minutes=10)\n\t\t# And now add the new 10-minute period with the cumulative total\n\t\tdata_in[timestamp] = data_in[last_timestamp] + Decimal(value_in)\n\t\tlast_timestamp = timestamp\n\n# This is where we'll gather the outgoing transaction data\ndata_out = OrderedDict()\n# Start it off with 0 at the time of the first incoming transaction\ndata_out[first_timestamp] = Decimal('0.0')\n# The reason I keep adding these silly *_timestamp variables is because I can't\n# do data_in.keys()[0] or data_in.keys()[-1], and I don't want to keep casting\n# them into lists.\nlast_out_timestamp = first_timestamp\n\nwith open(args.outgoing) as f:\n\toutgoing = csv.reader(f)\n\t# Skip CSV header row\n\tnext(outgoing)\n\tfor _,_,timestamp,_,_,_,_,value_in,value_out,_,_,_,_,_ in outgoing:\n\t\t# Sanity check, just in case\n\t\tassert not float(value_in)\n\t\t# Round the timestamp down to the last 10-minute mark\n\t\ttimestamp = datetime.utcfromtimestamp(int(timestamp))\n\t\trounded_minute = timestamp.minute // 10 * 10\n\t\ttimestamp = timestamp.replace(minute=rounded_minute, second=0, microsecond=0)\n\t\t# We've already had a transaction for this 10-minute period, add this one to it\n\t\tif timestamp in data_out:\n\t\t\tdata_out[timestamp] += Decimal(value_out)\n\t\t\tlast_out_timestamp = timestamp\n\t\t\tcontinue\n\t\t# Fill in 10-minute periods without transactions as we did for incoming\n\t\twhile last_out_timestamp + timedelta(minutes=10) < timestamp:\n\t\t\tdata_out[last_out_timestamp + timedelta(minutes=10)] = data_out[last_out_timestamp]\n\t\t\tlast_out_timestamp += timedelta(minutes=10)\n\t\t# And now add the new 10-minute period with the cumulative total\n\t\tdata_out[timestamp] = data_out[last_out_timestamp] + Decimal(value_in)\n\t\tlast_out_timestamp = timestamp\n\n# If the outgoing transactions end more than 10 minutes before\n# the incoming ones, fill in the empty periods at the end\nwhile last_out_timestamp < last_timestamp:\n\tdata_out[last_out_timestamp + timedelta(minutes=10)] = data_out[last_out_timestamp]\n\tlast_out_timestamp += timedelta(minutes=10)\n\t\n# Output our data in CSV format\nfor k, v in data_in.items():\n\tprint('%s,%s,%s' % (k, v, data_out[k]))",
 "title": ""
}